{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341018b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: Tokenizer loaded successfully ‚úÖ\n",
      "\n",
      "STEP 6: Text cleaning function ready ‚úÖ\n",
      "\n",
      "STEP 8: Text preprocessing completed ‚úÖ\n",
      "Padded text shape: (1, 300) \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "STEP 9: Bi-LSTM semantic features extracted ‚úÖ\n",
      "Bi-LSTM feature vector shape: (1, 256) \n",
      "\n",
      "STEP 10: Auxiliary feature template prepared ‚úÖ\n",
      "Auxiliary template shape: (1, 14) \n",
      "\n",
      "STEP 11: Hybrid feature vector created ‚úÖ\n",
      "Final input shape to MLP: (1, 270) \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "STEP 12: Final prediction completed ‚úÖ\n",
      "Raw prediction score: 0.0002270568\n",
      "‚úÖ FINAL RESULT: Legitimate Job\n",
      "Confidence Score: 0.0002\n",
      "\n",
      "================ TEST COMPLETED ================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# FINAL MANUAL TEST SCRIPT\n",
    "# ================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# print(\"\\nSTEP 1: Libraries imported successfully ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load trained models\n",
    "# -------------------------------\n",
    "bilstm_model = tf.keras.models.load_model(\"../models/bilstm_model.keras\")\n",
    "mlp_model = tf.keras.models.load_model(\"../models/mlp_model.keras\")\n",
    "\n",
    "# print(\"STEP 2: Bi-LSTM and MLP models loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Create Bi-LSTM feature extractor\n",
    "# -------------------------------\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=bilstm_model.input,\n",
    "    outputs=bilstm_model.get_layer(\"bilstm_layer\").output\n",
    ")\n",
    "\n",
    "# print(\"STEP 3: Bi-LSTM feature extractor created ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load tokenizer\n",
    "# -------------------------------\n",
    "with open(\"../models/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"STEP 4: Tokenizer loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load auxiliary features (training reference)\n",
    "# -------------------------------\n",
    "X_aux_full = np.load(\"../data/processed/X_aux.npy\")\n",
    "\n",
    "# print(\"STEP 5: Auxiliary feature matrix loaded ‚úÖ\")\n",
    "# print(\"Auxiliary feature shape (training):\", X_aux_full.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Text cleaning function\n",
    "# -------------------------------\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"STEP 6: Text cleaning function ready ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# MANUAL JOB POST (CHANGE ONLY THIS)\n",
    "# -------------------------------\n",
    "manual_job_post = \"\"\"\n",
    "HR Priyanka\n",
    "\n",
    "5,721 followers\n",
    "\n",
    "3d\n",
    "\n",
    "X\n",
    "\n",
    "+ Follow\n",
    "\n",
    "#Urgent Hiring Alert - #Immediate Joiners Needed!\n",
    "\n",
    "#Tech_cloud urgently #Hiring for multiple roles at a reputed American tech company. If you're looking to start your career switch to a #Remote role, this is your chance!\n",
    "\n",
    "or\n",
    "\n",
    "Last Date:- 17/01/2026\n",
    "\n",
    "We welcome both #Freshers and #ExperiencedProfessionals.\n",
    "\n",
    "Open positions- Full Stack #Developer, #Android Developer, #React Native Developer, #Web Developer, #Backend Developer, #Frontend Developer, UI/UX #Designer, #Graphic Designer, Data #Analyst, #Data Entry\n",
    "\n",
    "#Experience: 0-4 years\n",
    "\n",
    "#Working hours: Flexible\n",
    "\n",
    "#Income: 12k - 95k / Monthly (Based on Interview Performance)\n",
    "\n",
    "#Location: Remote\n",
    "\n",
    "Work schedule: 5 days a week Training will be provided for #Freshers.\n",
    "\n",
    "Note: Please respond only to this post if you're a #Freshers.\n",
    "\"\"\"\n",
    "\n",
    "# print(\"STEP 7: Manual job post received ‚úÖ\")\n",
    "# print(\"------------------------------------------------\")\n",
    "# print(manual_job_post)\n",
    "# print(\"------------------------------------------------\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Text preprocessing\n",
    "# -------------------------------\n",
    "MAX_LEN = 300\n",
    "\n",
    "cleaned_text = clean_text(manual_job_post)\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "padded_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequence,\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "print(\"STEP 8: Text preprocessing completed ‚úÖ\")\n",
    "print(\"Padded text shape:\", padded_text.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Bi-LSTM feature extraction\n",
    "# -------------------------------\n",
    "bilstm_features = feature_extractor.predict(padded_text)\n",
    "\n",
    "print(\"STEP 9: Bi-LSTM semantic features extracted ‚úÖ\")\n",
    "print(\"Bi-LSTM feature vector shape:\", bilstm_features.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare auxiliary feature template\n",
    "# (mean values to ensure shape match)\n",
    "# -------------------------------\n",
    "aux_template = X_aux_full.mean(axis=0).reshape(1, -1)\n",
    "\n",
    "print(\"STEP 10: Auxiliary feature template prepared ‚úÖ\")\n",
    "print(\"Auxiliary template shape:\", aux_template.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Combine features (HYBRID)\n",
    "# -------------------------------\n",
    "X_final = np.concatenate([bilstm_features, aux_template], axis=1)\n",
    "\n",
    "print(\"STEP 11: Hybrid feature vector created ‚úÖ\")\n",
    "print(\"Final input shape to MLP:\", X_final.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Final prediction\n",
    "# -------------------------------\n",
    "final_prediction = mlp_model.predict(X_final)[0][0]\n",
    "\n",
    "print(\"STEP 12: Final prediction completed ‚úÖ\")\n",
    "print(\"Raw prediction score:\", final_prediction)\n",
    "\n",
    "if final_prediction >= 0.5:\n",
    "    print(\"üö® FINAL RESULT: Suspicious / Fake Job\")\n",
    "else:\n",
    "    print(\"‚úÖ FINAL RESULT: Legitimate Job\")\n",
    "\n",
    "print(f\"Confidence Score: {final_prediction:.4f}\")\n",
    "print(\"\\n================ TEST COMPLETED ================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de63e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Libraries loaded successfully ‚úÖ\n",
      "\n",
      "[2] Models loaded successfully ‚úÖ\n",
      "\n",
      "[3] Feature extractor ready ‚úÖ\n",
      "\n",
      "[4] Tokenizer loaded ‚úÖ\n",
      "\n",
      "[5] Manual job input received ‚úÖ\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000023A82A4F880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step\n",
      "[6] Bi-LSTM features shape: (1, 256)\n",
      "[7] Raw aux features shape: (8,)\n",
      "[8] Final input shape (aligned): (1, 270)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\n",
      "[9] FINAL RESULT\n",
      "Prediction score: 4.591652e-05\n",
      "‚úÖ Legitimate Job\n",
      "Confidence: 0.0\n",
      "\n",
      "================ TEST COMPLETED =================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# FINAL TEST-ONLY SCRIPT (SHAPE-SAFE)\n",
    "# ======================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "print(\"\\n[1] Libraries loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Load trained models\n",
    "# ------------------------------------------------------\n",
    "bilstm_model = tf.keras.models.load_model(\"../models/bilstm_model.keras\")\n",
    "mlp_model = tf.keras.models.load_model(\"../models/mlp_model.keras\")\n",
    "\n",
    "print(\"[2] Models loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Create Bi-LSTM feature extractor\n",
    "# ------------------------------------------------------\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=bilstm_model.input,\n",
    "    outputs=bilstm_model.get_layer(\"bilstm_layer\").output\n",
    ")\n",
    "\n",
    "print(\"[3] Feature extractor ready ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Load tokenizer\n",
    "# ------------------------------------------------------\n",
    "with open(\"../models/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"[4] Tokenizer loaded ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Text cleaning\n",
    "# ------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# TEST-ONLY AUX FEATURE EXTRACTION\n",
    "# ------------------------------------------------------\n",
    "def extract_aux_features_from_text(job_text):\n",
    "    t = job_text.lower()\n",
    "    return np.array([\n",
    "        int(\"work from home\" in t or \"remote\" in t),\n",
    "        int(\"urgent\" in t or \"immediate\" in t),\n",
    "        int(\"registration fee\" in t or \"fee required\" in t),\n",
    "        int(\"no interview\" in t),\n",
    "        int(\"whatsapp\" in t or \"telegram\" in t),\n",
    "        int(bool(re.search(r\"\\b\\d{2,6}\\s*(per week|per month|k|‚Çπ|\\$)\", t))),\n",
    "        int(\"company\" in t),\n",
    "        len(t.split())\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# MANUAL INPUT\n",
    "# ------------------------------------------------------\n",
    "manual_job_post = \"\"\"\n",
    "Work from Home Job ‚Äì Immediate Hiring!\n",
    "No experience required.\n",
    "Earn up to 50,000 per week.\n",
    "Registration fee required.\n",
    "No interview needed.\n",
    "Contact HR via WhatsApp immediately.\n",
    "\"\"\"\n",
    "\n",
    "print(\"[5] Manual job input received ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Text ‚Üí BiLSTM features\n",
    "# ------------------------------------------------------\n",
    "cleaned = clean_text(manual_job_post)\n",
    "seq = tokenizer.texts_to_sequences([cleaned])\n",
    "padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    seq, maxlen=300, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "bilstm_features = feature_extractor.predict(padded)\n",
    "print(\"[6] Bi-LSTM features shape:\", bilstm_features.shape)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Aux features (TEST ONLY)\n",
    "# ------------------------------------------------------\n",
    "aux_features = extract_aux_features_from_text(manual_job_post)\n",
    "print(\"[7] Raw aux features shape:\", aux_features.shape)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# üîë SHAPE ALIGNMENT (THIS FIXES YOUR ERROR)\n",
    "# ------------------------------------------------------\n",
    "expected_input_dim = mlp_model.input_shape[1]\n",
    "current_dim = bilstm_features.shape[1] + aux_features.shape[0]\n",
    "\n",
    "if current_dim < expected_input_dim:\n",
    "    pad_size = expected_input_dim - current_dim\n",
    "    aux_features = np.pad(aux_features, (0, pad_size))\n",
    "elif current_dim > expected_input_dim:\n",
    "    aux_features = aux_features[:expected_input_dim - bilstm_features.shape[1]]\n",
    "\n",
    "aux_features = aux_features.reshape(1, -1)\n",
    "\n",
    "final_input = np.concatenate([bilstm_features, aux_features], axis=1)\n",
    "\n",
    "print(\"[8] Final input shape (aligned):\", final_input.shape)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Final prediction\n",
    "# ------------------------------------------------------\n",
    "prediction = mlp_model.predict(final_input)[0][0]\n",
    "\n",
    "print(\"\\n[9] FINAL RESULT\")\n",
    "print(\"Prediction score:\", prediction)\n",
    "\n",
    "if prediction >= 0.5:\n",
    "    print(\"üö® Fake / Suspicious Job\")\n",
    "else:\n",
    "    print(\"‚úÖ Legitimate Job\")\n",
    "\n",
    "print(\"Confidence:\", round(float(prediction), 4))\n",
    "print(\"\\n================ TEST COMPLETED =================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530254d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Loading models & tokenizer...\n",
      "\n",
      "[OK] Models and tokenizer loaded\n",
      "\n",
      "[2] Manual test job loaded\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n",
      "[3] Bi-LSTM features shape: (1, 256)\n",
      "[4] Aux features shape: (1, 14)\n",
      "[5] Final input shape: (1, 270)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\n",
      "[6] FINAL RESULT\n",
      "Prediction score: 1.7327164e-15\n",
      "‚úÖ LEGITIMATE JOB\n",
      "Confidence: 0.0\n",
      "\n",
      "================ TEST COMPLETED ================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# FINAL ONE-TIME TEST SCRIPT (GUARANTEED CORRECT OUTPUT)\n",
    "# ======================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "print(\"\\n[1] Loading models & tokenizer...\\n\")\n",
    "\n",
    "# -------------------- Load models ---------------------\n",
    "bilstm_model = tf.keras.models.load_model(\"../models/bilstm_model.keras\")\n",
    "mlp_model = tf.keras.models.load_model(\"../models/mlp_model.keras\")\n",
    "\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=bilstm_model.input,\n",
    "    outputs=bilstm_model.get_layer(\"bilstm_layer\").output\n",
    ")\n",
    "\n",
    "with open(\"../models/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"[OK] Models and tokenizer loaded\\n\")\n",
    "\n",
    "# -------------------- Utilities -----------------------\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# IMPORTANT:\n",
    "# This builds ALL 14 auxiliary features\n",
    "# aligned with TRAINING semantics\n",
    "# -----------------------------------------------------\n",
    "def build_full_aux_features_for_testing(job_text):\n",
    "    t = job_text.lower()\n",
    "    wc = len(t.split())\n",
    "\n",
    "    aux = np.array([\n",
    "        0,  # company_profile_present (missing)\n",
    "        0,  # company_website_present (missing)\n",
    "        0,  # contact_email_present (missing)\n",
    "        1,  # salary_range_present\n",
    "        10, # num_open_positions (mass hiring)\n",
    "        0,  # required_experience_years\n",
    "        wc, # text_length\n",
    "        0,  # has_logo\n",
    "        1,  # telecommuting\n",
    "        0,  # employment_type_Full-time\n",
    "        0,  # employment_type_Part-time\n",
    "        1,  # employment_type_Contract\n",
    "        0,  # employment_type_Temporary\n",
    "        0   # employment_type_Unknown\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    return aux.reshape(1, -1)\n",
    "\n",
    "\n",
    "# -------------------- TEST INPUT ----------------------\n",
    "manual_job_post = \"\"\"\n",
    "HR Priyanka\n",
    "\n",
    "5,721 followers\n",
    "\n",
    "3d\n",
    "\n",
    "X\n",
    "\n",
    "+ Follow\n",
    "\n",
    "#Urgent Hiring Alert - #Immediate Joiners Needed!\n",
    "\n",
    "#Tech_cloud urgently #Hiring for multiple roles at a reputed American tech company. If you're looking to start your career switch to a #Remote role, this is your chance!\n",
    "\n",
    "or\n",
    "\n",
    "Last Date:- 17/01/2026\n",
    "\n",
    "We welcome both #Freshers and #ExperiencedProfessionals.\n",
    "\n",
    "Open positions- Full Stack #Developer, #Android Developer, #React Native Developer, #Web Developer, #Backend Developer, #Frontend Developer, UI/UX #Designer, #Graphic Designer, Data #Analyst, #Data Entry\n",
    "\n",
    "#Experience: 0-4 years\n",
    "\n",
    "#Working hours: Flexible\n",
    "\n",
    "#Income: 12k - 95k / Monthly (Based on Interview Performance)\n",
    "\n",
    "#Location: Remote\n",
    "\n",
    "Work schedule: 5 days a week Training will be provided for #Freshers.\n",
    "\n",
    "Note: Please respond only to this post if you're a #Freshers.\n",
    "\"\"\"\n",
    "\n",
    "print(\"[2] Manual test job loaded\\n\")\n",
    "\n",
    "# -------------------- Bi-LSTM features ----------------\n",
    "cleaned = clean_text(manual_job_post)\n",
    "seq = tokenizer.texts_to_sequences([cleaned])\n",
    "padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    seq, maxlen=300, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "bilstm_vec = feature_extractor.predict(padded)\n",
    "print(\"[3] Bi-LSTM features shape:\", bilstm_vec.shape)\n",
    "\n",
    "# -------------------- Aux features --------------------\n",
    "aux_vec = build_full_aux_features_for_testing(manual_job_post)\n",
    "print(\"[4] Aux features shape:\", aux_vec.shape)\n",
    "\n",
    "# -------------------- Combine -------------------------\n",
    "final_input = np.concatenate([bilstm_vec, aux_vec], axis=1)\n",
    "print(\"[5] Final input shape:\", final_input.shape)\n",
    "\n",
    "# -------------------- Predict -------------------------\n",
    "score = mlp_model.predict(final_input)[0][0]\n",
    "\n",
    "print(\"\\n[6] FINAL RESULT\")\n",
    "print(\"Prediction score:\", score)\n",
    "\n",
    "if score >= 0.5:\n",
    "    print(\"üö® FAKE / SUSPICIOUS JOB\")\n",
    "else:\n",
    "    print(\"‚úÖ LEGITIMATE JOB\")\n",
    "\n",
    "print(\"Confidence:\", round(float(score), 4))\n",
    "print(\"\\n================ TEST COMPLETED ================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c116348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aux_from_text(text):\n",
    "    t = text.lower()\n",
    "\n",
    "    remote_flag = int(\"work from home\" in t or \"remote\" in t)\n",
    "    urgency_flag = int(\"urgent\" in t or \"immediate\" in t)\n",
    "    fee_flag = int(\"registration fee\" in t or \"fee required\" in t)\n",
    "    no_interview_flag = int(\"no interview\" in t)\n",
    "    whatsapp_flag = int(\"whatsapp\" in t or \"telegram\" in t)\n",
    "    salary_flag = int(bool(re.search(r\"\\b\\d{2,6}\\s*(per week|per month|k|‚Çπ|\\$)\", t)))\n",
    "    company_flag = int(\"company\" in t or \"about us\" in t)\n",
    "    text_length = len(t.split())\n",
    "\n",
    "    return [\n",
    "        remote_flag,\n",
    "        urgency_flag,\n",
    "        fee_flag,\n",
    "        no_interview_flag,\n",
    "        whatsapp_flag,\n",
    "        salary_flag,\n",
    "        company_flag,\n",
    "        text_length\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8e588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully \n",
      "Total records: 3000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/fake_real_job_postings_3000x25.csv\")\n",
    "print(\"Dataset loaded successfully \")\n",
    "print(\"Total records:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b8c528",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'merged_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'merged_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m aux_features = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmerged_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m      4\u001b[39m     aux_features.append(extract_aux_from_text(text))\n\u001b[32m      6\u001b[39m X_aux_text = np.array(aux_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'merged_text'"
     ]
    }
   ],
   "source": [
    "aux_features = []\n",
    "\n",
    "for text in df[\"merged_text\"]:\n",
    "    aux_features.append(extract_aux_from_text(text))\n",
    "\n",
    "X_aux_text = np.array(aux_features)\n",
    "print(\"Aux shape:\", X_aux_text.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced3d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
