{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "341018b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 1: Libraries imported successfully ‚úÖ\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 11 variables whereas the saved optimizer has 20 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Bi-LSTM and MLP models loaded successfully ‚úÖ\n",
      "\n",
      "STEP 3: Bi-LSTM feature extractor created ‚úÖ\n",
      "\n",
      "STEP 4: Tokenizer loaded successfully ‚úÖ\n",
      "\n",
      "STEP 5: Auxiliary feature matrix loaded ‚úÖ\n",
      "Auxiliary feature shape (training): (3000, 14) \n",
      "\n",
      "STEP 6: Text cleaning function ready ‚úÖ\n",
      "\n",
      "STEP 7: Manual job post received ‚úÖ\n",
      "------------------------------------------------\n",
      "\n",
      "Work from Home Job ‚Äì Immediate Hiring!\n",
      "\n",
      "No experience required.\n",
      "Earn up to 50,000 per week.\n",
      "Registration fee required.\n",
      "No interview needed.\n",
      "Contact HR via WhatsApp immediately.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "STEP 8: Text preprocessing completed ‚úÖ\n",
      "Padded text shape: (1, 300) \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step\n",
      "STEP 9: Bi-LSTM semantic features extracted ‚úÖ\n",
      "Bi-LSTM feature vector shape: (1, 256) \n",
      "\n",
      "STEP 10: Auxiliary feature template prepared ‚úÖ\n",
      "Auxiliary template shape: (1, 14) \n",
      "\n",
      "STEP 11: Hybrid feature vector created ‚úÖ\n",
      "Final input shape to MLP: (1, 270) \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "STEP 12: Final prediction completed ‚úÖ\n",
      "Raw prediction score: 0.0067415913\n",
      "‚úÖ FINAL RESULT: Legitimate Job\n",
      "Confidence Score: 0.0067\n",
      "\n",
      "================ TEST COMPLETED ================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# FINAL MANUAL TEST SCRIPT\n",
    "# ================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "print(\"\\nSTEP 1: Libraries imported successfully ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load trained models\n",
    "# -------------------------------\n",
    "bilstm_model = tf.keras.models.load_model(\"../models/bilstm_model.keras\")\n",
    "mlp_model = tf.keras.models.load_model(\"../models/mlp_model.keras\")\n",
    "\n",
    "print(\"STEP 2: Bi-LSTM and MLP models loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Create Bi-LSTM feature extractor\n",
    "# -------------------------------\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=bilstm_model.input,\n",
    "    outputs=bilstm_model.get_layer(\"bilstm_layer\").output\n",
    ")\n",
    "\n",
    "print(\"STEP 3: Bi-LSTM feature extractor created ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load tokenizer\n",
    "# -------------------------------\n",
    "with open(\"../models/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"STEP 4: Tokenizer loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load auxiliary features (training reference)\n",
    "# -------------------------------\n",
    "X_aux_full = np.load(\"../data/processed/X_aux.npy\")\n",
    "\n",
    "print(\"STEP 5: Auxiliary feature matrix loaded ‚úÖ\")\n",
    "print(\"Auxiliary feature shape (training):\", X_aux_full.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Text cleaning function\n",
    "# -------------------------------\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"STEP 6: Text cleaning function ready ‚úÖ\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# MANUAL JOB POST (CHANGE ONLY THIS)\n",
    "# -------------------------------\n",
    "manual_job_post = \"\"\"\n",
    "Work from Home Job ‚Äì Immediate Hiring!\n",
    "\n",
    "No experience required.\n",
    "Earn up to 50,000 per week.\n",
    "Registration fee required.\n",
    "No interview needed.\n",
    "Contact HR via WhatsApp immediately.\n",
    "\"\"\"\n",
    "\n",
    "print(\"STEP 7: Manual job post received ‚úÖ\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(manual_job_post)\n",
    "print(\"------------------------------------------------\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Text preprocessing\n",
    "# -------------------------------\n",
    "MAX_LEN = 300\n",
    "\n",
    "cleaned_text = clean_text(manual_job_post)\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "padded_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequence,\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "print(\"STEP 8: Text preprocessing completed ‚úÖ\")\n",
    "print(\"Padded text shape:\", padded_text.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Bi-LSTM feature extraction\n",
    "# -------------------------------\n",
    "bilstm_features = feature_extractor.predict(padded_text)\n",
    "\n",
    "print(\"STEP 9: Bi-LSTM semantic features extracted ‚úÖ\")\n",
    "print(\"Bi-LSTM feature vector shape:\", bilstm_features.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare auxiliary feature template\n",
    "# (mean values to ensure shape match)\n",
    "# -------------------------------\n",
    "aux_template = X_aux_full.mean(axis=0).reshape(1, -1)\n",
    "\n",
    "print(\"STEP 10: Auxiliary feature template prepared ‚úÖ\")\n",
    "print(\"Auxiliary template shape:\", aux_template.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Combine features (HYBRID)\n",
    "# -------------------------------\n",
    "X_final = np.concatenate([bilstm_features, aux_template], axis=1)\n",
    "\n",
    "print(\"STEP 11: Hybrid feature vector created ‚úÖ\")\n",
    "print(\"Final input shape to MLP:\", X_final.shape, \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Final prediction\n",
    "# -------------------------------\n",
    "final_prediction = mlp_model.predict(X_final)[0][0]\n",
    "\n",
    "print(\"STEP 12: Final prediction completed ‚úÖ\")\n",
    "print(\"Raw prediction score:\", final_prediction)\n",
    "\n",
    "if final_prediction >= 0.5:\n",
    "    print(\"üö® FINAL RESULT: Suspicious / Fake Job\")\n",
    "else:\n",
    "    print(\"‚úÖ FINAL RESULT: Legitimate Job\")\n",
    "\n",
    "print(f\"Confidence Score: {final_prediction:.4f}\")\n",
    "print(\"\\n================ TEST COMPLETED ================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de63e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Libraries loaded successfully ‚úÖ\n",
      "\n",
      "[2] Models loaded successfully ‚úÖ\n",
      "\n",
      "[3] Feature extractor ready ‚úÖ\n",
      "\n",
      "[4] Tokenizer loaded ‚úÖ\n",
      "\n",
      "[5] Manual job input received ‚úÖ\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000023A82A4F880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step\n",
      "[6] Bi-LSTM features shape: (1, 256)\n",
      "[7] Raw aux features shape: (8,)\n",
      "[8] Final input shape (aligned): (1, 270)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\n",
      "[9] FINAL RESULT\n",
      "Prediction score: 4.591652e-05\n",
      "‚úÖ Legitimate Job\n",
      "Confidence: 0.0\n",
      "\n",
      "================ TEST COMPLETED =================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# FINAL TEST-ONLY SCRIPT (SHAPE-SAFE)\n",
    "# ======================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "print(\"\\n[1] Libraries loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Load trained models\n",
    "# ------------------------------------------------------\n",
    "bilstm_model = tf.keras.models.load_model(\"../models/bilstm_model.keras\")\n",
    "mlp_model = tf.keras.models.load_model(\"../models/mlp_model.keras\")\n",
    "\n",
    "print(\"[2] Models loaded successfully ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Create Bi-LSTM feature extractor\n",
    "# ------------------------------------------------------\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=bilstm_model.input,\n",
    "    outputs=bilstm_model.get_layer(\"bilstm_layer\").output\n",
    ")\n",
    "\n",
    "print(\"[3] Feature extractor ready ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Load tokenizer\n",
    "# ------------------------------------------------------\n",
    "with open(\"../models/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"[4] Tokenizer loaded ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Text cleaning\n",
    "# ------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# TEST-ONLY AUX FEATURE EXTRACTION\n",
    "# ------------------------------------------------------\n",
    "def extract_aux_features_from_text(job_text):\n",
    "    t = job_text.lower()\n",
    "    return np.array([\n",
    "        int(\"work from home\" in t or \"remote\" in t),\n",
    "        int(\"urgent\" in t or \"immediate\" in t),\n",
    "        int(\"registration fee\" in t or \"fee required\" in t),\n",
    "        int(\"no interview\" in t),\n",
    "        int(\"whatsapp\" in t or \"telegram\" in t),\n",
    "        int(bool(re.search(r\"\\b\\d{2,6}\\s*(per week|per month|k|‚Çπ|\\$)\", t))),\n",
    "        int(\"company\" in t),\n",
    "        len(t.split())\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# MANUAL INPUT\n",
    "# ------------------------------------------------------\n",
    "manual_job_post = \"\"\"\n",
    "Work from Home Job ‚Äì Immediate Hiring!\n",
    "No experience required.\n",
    "Earn up to 50,000 per week.\n",
    "Registration fee required.\n",
    "No interview needed.\n",
    "Contact HR via WhatsApp immediately.\n",
    "\"\"\"\n",
    "\n",
    "print(\"[5] Manual job input received ‚úÖ\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Text ‚Üí BiLSTM features\n",
    "# ------------------------------------------------------\n",
    "cleaned = clean_text(manual_job_post)\n",
    "seq = tokenizer.texts_to_sequences([cleaned])\n",
    "padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    seq, maxlen=300, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "bilstm_features = feature_extractor.predict(padded)\n",
    "print(\"[6] Bi-LSTM features shape:\", bilstm_features.shape)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Aux features (TEST ONLY)\n",
    "# ------------------------------------------------------\n",
    "aux_features = extract_aux_features_from_text(manual_job_post)\n",
    "print(\"[7] Raw aux features shape:\", aux_features.shape)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# üîë SHAPE ALIGNMENT (THIS FIXES YOUR ERROR)\n",
    "# ------------------------------------------------------\n",
    "expected_input_dim = mlp_model.input_shape[1]\n",
    "current_dim = bilstm_features.shape[1] + aux_features.shape[0]\n",
    "\n",
    "if current_dim < expected_input_dim:\n",
    "    pad_size = expected_input_dim - current_dim\n",
    "    aux_features = np.pad(aux_features, (0, pad_size))\n",
    "elif current_dim > expected_input_dim:\n",
    "    aux_features = aux_features[:expected_input_dim - bilstm_features.shape[1]]\n",
    "\n",
    "aux_features = aux_features.reshape(1, -1)\n",
    "\n",
    "final_input = np.concatenate([bilstm_features, aux_features], axis=1)\n",
    "\n",
    "print(\"[8] Final input shape (aligned):\", final_input.shape)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Final prediction\n",
    "# ------------------------------------------------------\n",
    "prediction = mlp_model.predict(final_input)[0][0]\n",
    "\n",
    "print(\"\\n[9] FINAL RESULT\")\n",
    "print(\"Prediction score:\", prediction)\n",
    "\n",
    "if prediction >= 0.5:\n",
    "    print(\"üö® Fake / Suspicious Job\")\n",
    "else:\n",
    "    print(\"‚úÖ Legitimate Job\")\n",
    "\n",
    "print(\"Confidence:\", round(float(prediction), 4))\n",
    "print(\"\\n================ TEST COMPLETED =================\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
