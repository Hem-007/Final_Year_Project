{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b3cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "print(\"Libraries imported successfully \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d0b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:\n",
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\")\n",
    "print(\"Hello world\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f85940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 11 variables whereas the saved optimizer has 20 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-LSTM model loaded \n",
      "MLP decision model loaded \n"
     ]
    }
   ],
   "source": [
    "bilstm_model = tf.keras.models.load_model(\"../models/bilstm_model.keras\")\n",
    "mlp_model = tf.keras.models.load_model(\"../models/mlp_model.keras\")\n",
    "\n",
    "print(\"Bi-LSTM model loaded \")\n",
    "print(\"MLP decision model loaded \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62837fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-LSTM feature extractor created\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=bilstm_model.input,\n",
    "    outputs=bilstm_model.get_layer(\"bilstm_layer\").output\n",
    ")\n",
    "\n",
    "print(\"Bi-LSTM feature extractor created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ceb8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded successfully\n"
     ]
    }
   ],
   "source": [
    "with open(\"../models/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "scaler = pickle.load(open(\"models/aux_scaler.pkl\", \"rb\")) if False else None\n",
    "\n",
    "print(\"Tokenizer loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3779323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning function ready\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"Text cleaning function ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c48eaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual job post received \n"
     ]
    }
   ],
   "source": [
    "manual_job_post = \"\"\"\n",
    "Urgent Hiring Alert ‚Äì Immediate Joiners Needed!\n",
    "Multiple roles available including Developer, Designer, Data Analyst.\n",
    "Remote work with flexible hours.\n",
    "Salary range from 12k to 95k per month.\n",
    "Freshers and experienced candidates are welcome.\n",
    "Apply immediately.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Manual job post received \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c067b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing completed ‚úÖ\n",
      "Padded text shape: (1, 300)\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 300\n",
    "\n",
    "cleaned_text = clean_text(manual_job_post)\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "padded_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequence, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "print(\"Text preprocessing completed ‚úÖ\")\n",
    "print(\"Padded text shape:\", padded_text.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ac46b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "Bi-LSTM semantic features extracted\n",
      "Bi-LSTM feature vector shape: (1, 256)\n"
     ]
    }
   ],
   "source": [
    "bilstm_features = feature_extractor.predict(padded_text)\n",
    "\n",
    "print(\"Bi-LSTM semantic features extracted\")\n",
    "print(\"Bi-LSTM feature vector shape:\", bilstm_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63efb299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auxiliary features prepared\n",
      "Auxiliary feature shape: (1, 9)\n"
     ]
    }
   ],
   "source": [
    "aux_features_demo = np.array([\n",
    "    [\n",
    "        0,  # company_profile_present\n",
    "        0,  # company_website_present\n",
    "        0,  # contact_email_present\n",
    "        1,  # salary_range_present\n",
    "        10, # num_open_positions\n",
    "        0,  # required_experience_years\n",
    "        len(manual_job_post.split()),  # text_length\n",
    "        1,  # has_logo (assumed)\n",
    "        1   # telecommuting\n",
    "    ]\n",
    "])\n",
    "\n",
    "print(\"Auxiliary features prepared\")\n",
    "print(\"Auxiliary feature shape:\", aux_features_demo.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbda138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid feature vector created\n",
      "Final input shape to MLP: (1, 265)\n"
     ]
    }
   ],
   "source": [
    "X_final_demo = np.concatenate([bilstm_features, aux_features_demo], axis=1)\n",
    "\n",
    "print(\"Hybrid feature vector created\")\n",
    "print(\"Final input shape to MLP:\", X_final_demo.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364be4e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 270, but received input with shape (1, 265)\u001b[0m\n\nArguments received by Sequential.call():\n  ‚Ä¢ inputs=tf.Tensor(shape=(1, 265), dtype=float32)\n  ‚Ä¢ training=False\n  ‚Ä¢ mask=None\n  ‚Ä¢ kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m final_prediction = \u001b[43mmlp_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_final_demo\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal prediction score:\u001b[39m\u001b[33m\"\u001b[39m, final_prediction)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec.axes.items():\n\u001b[32m    223\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    224\u001b[39m             value,\n\u001b[32m    225\u001b[39m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    226\u001b[39m         }:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    228\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    229\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    230\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbut received input with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    232\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    233\u001b[39m             )\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 270, but received input with shape (1, 265)\u001b[0m\n\nArguments received by Sequential.call():\n  ‚Ä¢ inputs=tf.Tensor(shape=(1, 265), dtype=float32)\n  ‚Ä¢ training=False\n  ‚Ä¢ mask=None\n  ‚Ä¢ kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "final_prediction = mlp_model.predict(X_final_demo)[0][0]\n",
    "\n",
    "print(\"Final prediction score:\", final_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32da8e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auxiliary feature matrix loaded ‚úÖ\n",
      "Aux feature shape (training): (3000, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load full auxiliary feature matrix used during training\n",
    "X_aux_full = np.load(\"../data/processed/X_aux.npy\")\n",
    "\n",
    "print(\"Auxiliary feature matrix loaded ‚úÖ\")\n",
    "print(\"Aux feature shape (training):\", X_aux_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044548c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auxiliary feature template created ‚úÖ\n",
      "Aux template shape: (1, 14)\n"
     ]
    }
   ],
   "source": [
    "# Use mean auxiliary feature values as a neutral template\n",
    "aux_template = X_aux_full.mean(axis=0).reshape(1, -1)\n",
    "\n",
    "print(\"Auxiliary feature template created ‚úÖ\")\n",
    "print(\"Aux template shape:\", aux_template.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da43ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid feature vector created ‚úÖ\n",
      "Final input shape to MLP: (1, 270)\n"
     ]
    }
   ],
   "source": [
    "X_final_demo = np.concatenate(\n",
    "    [bilstm_features, aux_template],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Hybrid feature vector created ‚úÖ\")\n",
    "print(\"Final input shape to MLP:\", X_final_demo.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd151f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Final prediction score: 2.435433e-06\n",
      "‚úÖ FINAL RESULT: Legitimate Job\n",
      "Confidence Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "final_prediction = mlp_model.predict(X_final_demo)[0][0]\n",
    "\n",
    "print(\"Final prediction score:\", final_prediction)\n",
    "\n",
    "if final_prediction >= 0.5:\n",
    "    print(\"üö® FINAL RESULT: Suspicious / Fake Job\")\n",
    "else:\n",
    "    print(\"‚úÖ FINAL RESULT: Legitimate Job\")\n",
    "\n",
    "print(f\"Confidence Score: {final_prediction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e1090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb2782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9e02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc02d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Raw Prediction Score: 0.009917326\n",
      "Prediction: ‚úÖ Legitimate Job\n",
      "Confidence Score: 0.01\n"
     ]
    }
   ],
   "source": [
    "# manual_job_text = \"\"\"\n",
    "# HR Priyanka\n",
    "\n",
    "# 5,721 followers\n",
    "\n",
    "# 3d\n",
    "\n",
    "# X\n",
    "\n",
    "# + Follow\n",
    "\n",
    "# #Urgent Hiring Alert - #Immediate Joiners Needed!\n",
    "\n",
    "# #Tech_cloud urgently #Hiring for multiple roles at a reputed American tech company. If you're looking to start your career switch to a #Remote role, this is your chance!\n",
    "\n",
    "# or\n",
    "\n",
    "# Last Date:- 17/01/2026\n",
    "\n",
    "# We welcome both #Freshers and #ExperiencedProfessionals.\n",
    "\n",
    "# Open positions- Full Stack #Developer, #Android Developer, #React Native Developer, #Web Developer, #Backend Developer, #Frontend Developer, UI/UX #Designer, #Graphic Designer, Data #Analyst, #Data Entry\n",
    "\n",
    "# #Experience: 0-4 years\n",
    "\n",
    "# #Working hours: Flexible\n",
    "\n",
    "# #Income: 12k - 95k / Monthly (Based on Interview Performance)\n",
    "\n",
    "# #Location: Remote\n",
    "\n",
    "# Work schedule: 5 days a week Training will be provided for #Freshers.\n",
    "\n",
    "# Note: Please respond only to this post if you're a #Freshers.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# MAX_LEN = 300\n",
    "\n",
    "# cleaned_text = clean_text(manual_job_text)\n",
    "\n",
    "# sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "\n",
    "# padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#     sequence,\n",
    "#     maxlen=MAX_LEN,\n",
    "#     padding=\"post\",\n",
    "#     truncating=\"post\"\n",
    "# )\n",
    "\n",
    "\n",
    "# prediction = bilstm_model.predict(padded_sequence)[0][0]\n",
    "\n",
    "# print(\"Raw Prediction Score:\", prediction)\n",
    "\n",
    "\n",
    "# if prediction >= 0.5:\n",
    "#     print(\"Prediction: üö® Suspicious / Fake Job\")\n",
    "# else:\n",
    "#     print(\"Prediction: ‚úÖ Legitimate Job\")\n",
    "\n",
    "# print(f\"Confidence Score: {prediction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33d670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
