{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26962c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/fake_real_job_postings_3000x25.csv\")\n",
    "df.head()\n",
    "\n",
    "df.columns\n",
    "df[\"company_profile_present\"] = df[\"company_profile\"].notna().astype(int)\n",
    "df[\"company_website_present\"] = df[\"company_website\"].notna().astype(int)\n",
    "df[\"contact_email_present\"] = df[\"contact_email\"].notna().astype(int)\n",
    "df[\"salary_range_present\"] = df[\"salary_range\"].notna().astype(int)\n",
    "\n",
    "binary_features = df[\n",
    "    [\"has_logo\", \"telecommuting\"]\n",
    "].fillna(0)\n",
    "\n",
    "df[[\"job_id\",\"has_logo\", \"telecommuting\",\"company_profile_present\", \"company_website_present\", \"contact_email_present\", \"salary_range_present\"]]\n",
    "df[\"num_open_positions\"] = df[\"num_open_positions\"].fillna(0)\n",
    "df[\"required_experience_years\"] = df[\"required_experience_years\"].fillna(0)\n",
    "df[\"text_length\"] = df[\"text_length\"].fillna(0)\n",
    "\n",
    "df[\"employment_type\"] = df[\"employment_type\"].fillna(\"Unknown\")\n",
    "\n",
    "employment_type_encoded = pd.get_dummies(\n",
    "    df[\"employment_type\"],\n",
    "    prefix=\"employment_type\"\n",
    ")\n",
    "\n",
    "X_aux = pd.concat(\n",
    "    [\n",
    "        df[\n",
    "            [\n",
    "                \"company_profile_present\",\n",
    "                \"company_website_present\",\n",
    "                \"contact_email_present\",\n",
    "                \"salary_range_present\",\n",
    "                \"num_open_positions\",\n",
    "                \"required_experience_years\",\n",
    "                \"text_length\"\n",
    "            ]\n",
    "        ],\n",
    "        binary_features,\n",
    "        employment_type_encoded\n",
    "    ],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_aux_scaled = scaler.fit_transform(X_aux)\n",
    "\n",
    "np.save(\"../data/processed/X_aux.npy\", X_aux_scaled)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "    \n",
    "bilstm_model = tf.keras.models.load_model(\"../models/bilstm_model.keras\")\n",
    "print(\"Bi-LSTM model loaded successfully ✅\")\n",
    "\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=bilstm_model.input,\n",
    "    outputs=bilstm_model.get_layer(\"bilstm_layer\").output\n",
    ")\n",
    "\n",
    "print(\"Feature extractor created from Bi-LSTM layer \")\n",
    "\n",
    "with open(\"../models/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"Tokenizer loaded successfully \")\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/fake_real_job_postings_3000x25.csv\")\n",
    "print(\"Dataset loaded successfully \")\n",
    "print(\"Total records:\", len(df))\n",
    "\n",
    "text_columns = [\"job_title\", \"job_description\", \"requirements\", \"benefits\"]\n",
    "df[text_columns] = df[text_columns].fillna(\"\")\n",
    "\n",
    "df[\"merged_text\"] = (\n",
    "    df[\"job_title\"] + \" \" +\n",
    "    df[\"job_description\"] + \" \" +\n",
    "    df[\"requirements\"] + \" \" +\n",
    "    df[\"benefits\"]\n",
    ")\n",
    "\n",
    "print(\"Text columns merged successfully \")\n",
    "print(\"Sample merged text:\\n\")\n",
    "print(df[\"merged_text\"].iloc[0][:300], \"...\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"merged_text\"].apply(clean_text)\n",
    "\n",
    "print(\"Text cleaned successfully\")\n",
    "print(\"Sample cleaned text:\\n\")\n",
    "print(df[\"clean_text\"].iloc[0][:300], \"...\")\n",
    "\n",
    "MAX_LEN = 300\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df[\"clean_text\"])\n",
    "X_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences,\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "print(\"Text tokenized and padded successfully \")\n",
    "print(\"Text tensor shape:\", X_text.shape)\n",
    "\n",
    "X_bilstm_features = feature_extractor.predict(X_text, batch_size=32)\n",
    "\n",
    "print(\"Bi-LSTM feature extraction completed ✅\")\n",
    "print(\"Feature vector shape:\", X_bilstm_features.shape)\n",
    "\n",
    "np.save(\"../data/processed/X_bilstm_features.npy\", X_bilstm_features)\n",
    "\n",
    "print(\"Bi-LSTM feature vectors saved successfully \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a92c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully ✅\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Libraries imported successfully ✅\")\n",
    "\n",
    "X_bilstm = np.load(\"../data/processed/X_bilstm_features.npy\")\n",
    "print(\"Bi-LSTM feature vectors loaded \")\n",
    "print(\"Bi-LSTM feature shape:\", X_bilstm.shape)\n",
    "X_aux = np.load(\"../data/processed/X_aux.npy\")\n",
    "print(\"Auxiliary features loaded \")\n",
    "print(\"Auxiliary feature shape:\", X_aux.shape)\n",
    "X_final = np.concatenate([X_bilstm, X_aux], axis=1)\n",
    "\n",
    "print(\"Bi-LSTM + Auxiliary features combined successfully \")\n",
    "print(\"Final feature vector shape:\", X_final.shape)\n",
    "\n",
    "\n",
    "\n",
    "y = pd.read_csv(\"../data/raw/fake_real_job_postings_3000x25.csv\")[\"is_fake\"].values\n",
    "\n",
    "print(\"Labels loaded successfully \")\n",
    "print(\"Total labels:\", len(y))\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_final, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Dataset split completed \")\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Validation samples:\", X_val.shape[0])\n",
    "print(\"Testing samples:\", X_test.shape[0])\n",
    "\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_final.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "print(\"MLP model architecture created \")\n",
    "\n",
    "mlp_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "mlp_model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "print(\"MLP training started...............! \")\n",
    "\n",
    "\n",
    "history = mlp_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "print(\"MLP training completed successfully \")\n",
    "\n",
    "test_loss, test_accuracy = mlp_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Final MLP Test Accuracy:\", test_accuracy)\n",
    "print(\"Final MLP Test Loss:\", test_loss)\n",
    "\n",
    "mlp_model.save(\"../models/mlp_model.keras\")\n",
    "print(\"MLP model saved successfully ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e0fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85490a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
